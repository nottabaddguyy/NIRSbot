import logging
import pandas as pd
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import text_processing as tp

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

df = None
vectorizer = TfidfVectorizer()
tfidf_matrix = None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑŽ."""
    await update.message.reply_text(
        "ðŸ‘‹ Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ Ð±Ð¾Ñ‚ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… ÑÑ‚Ð°Ñ‚ÐµÐ¹.\n"
        "ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‰ÑƒÑŽ Ð²Ð°Ñ Ñ‚ÐµÐ¼Ñƒ, Ð¸ Ñ Ð½Ð°Ð¹Ð´Ñƒ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸.\n"
        "ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ NLP")

async def search_articles(query: str) -> list:
    global df, vectorizer, tfidf_matrix

    processed_query = tp.preprocess(query)
    query_vec = vectorizer.transform([processed_query])
    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()

    top_indices = similarities.argsort()[-5:][::-1]
    results = []
    for idx in top_indices:
        score = similarities[idx]
        if score > 0.1: 
            row = df.iloc[idx]
            results.append({
                'title': row['title'],
                'authors': row['authors'],
                'subject': row['subject'],
                'abstract': row['abstract'][:200] + '...',  
                'url': row['url'],
                'score': round(score, 3)})
    return results

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    query = update.message.text
    await update.message.reply_text("Ð˜Ñ‰Ñƒ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸...")

    results = await search_articles(query)
    if not results:
        await update.message.reply_text("Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾Ñ.")
        return

    response = f"ÐÐ°ÑˆÑ‘Ð» {len(results)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ:\n\n"
    for i, art in enumerate(results, 1):
        response += (
            f"{i}. *{art['title']}*\n"
            f"   ÐÐ²Ñ‚Ð¾Ñ€Ñ‹: {art['authors']}\n"
            f"   Ð ÑƒÐ±Ñ€Ð¸ÐºÐ° Ð’Ð˜ÐÐ˜Ð¢Ð˜: {art['subject']}\n"
            f"   ÐÐ½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ñ: {art['abstract']}\n"
            f"   [Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° ÑÑ‚Ð°Ñ‚ÑŒÑŽ]({art['url']})\n\n")

    await update.message.reply_text(response, parse_mode='Markdown')

def load_data():
    global df, vectorizer, tfidf_matrix

    df = pd.read_csv('data.csv', encoding='utf-8')
    # ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²ÑÐµÑ… Ð°Ð½Ð½Ð¾Ñ‚Ð°Ñ†Ð¸Ð¹
    processed_abstracts = [tp.preprocess(text) for text in df['abstract']]
    # ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ð¹ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ
    tfidf_matrix = vectorizer.fit_transform(processed_abstracts)
    logger.info(f"Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(df)} ÑÑ‚Ð°Ñ‚ÐµÐ¹, Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð¼ {tfidf_matrix.shape}")

def main() -> None:
    
    TOKEN = '8479188706:AAFoW95ye91E4Ng6rpJP8NO4_iuT97hXdzs'

    load_data()

    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()