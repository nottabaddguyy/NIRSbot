import logging
import pandas as pd
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import text_processing as tp

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

df = None
vectorizer = TfidfVectorizer()
tfidf_matrix = None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é."""
    await update.message.reply_text(
        "üëã –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –±–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.\n"
        "–ù–∞–ø–∏—à–∏—Ç–µ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â—É—é –≤–∞—Å —Ç–µ–º—É, –∏ —è –Ω–∞–π–¥—É –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä: –º–µ—Ç–æ–¥—ã NLP")

async def search_articles(query: str) -> list:
    global df, vectorizer, tfidf_matrix

    processed_query = tp.preprocess(query)
    query_vec = vectorizer.transform([processed_query])
    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()

    top_indices = similarities.argsort()[-5:][::-1]
    results = []
    for idx in top_indices:
        score = similarities[idx]
        if score > 0.1: 
            row = df.iloc[idx]
            results.append({
                'title': row['title'],
                'authors': row['authors'],
                'subject': row['subject'],
                'abstract': row['abstract'][:200] + '...',  
                'url': row['url'],
                'score': round(score, 3)})
    return results

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    query = update.message.text
    await update.message.reply_text("–ò—â—É –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Å—Ç–∞—Ç—å–∏...")

    results = await search_articles(query)
    if not results:
        await update.message.reply_text("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.")
        return

    response = f"–ù–∞—à—ë–ª {len(results)} —Å—Ç–∞—Ç–µ–π –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É:\n\n"
    for i, art in enumerate(results, 1):
        response += (
            f"{i}. *{art['title']}*\n"
            f"   –ê–≤—Ç–æ—Ä—ã: {art['authors']}\n"
            f"   –†—É–±—Ä–∏–∫–∞ –í–ò–ù–ò–¢–ò: {art['subject']}\n"
            f"   –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {art['abstract']}\n"
            f"   [–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é]({art['url']})\n\n")

    await update.message.reply_text(response, parse_mode='Markdown')

def load_data():
    global df, vectorizer, tfidf_matrix

    df = pd.read_csv('data.csv', encoding='utf-8')
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    processed_abstracts = [tp.preprocess(text) for text in df['abstract']]
    # –û–±—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å
    tfidf_matrix = vectorizer.fit_transform(processed_abstracts)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç–∞—Ç–µ–π, –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º {tfidf_matrix.shape}")

def main() -> None:
    
    TOKEN = '–í—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–∫–µ–Ω'

    load_data()

    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
